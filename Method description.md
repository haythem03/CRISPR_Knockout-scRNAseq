# Method Description

Our approach combines k-Nearest Neighbor (k-NN) similarity-based expression prediction with XGBoost regression for cell program proportions. For expression prediction, we compute 14-dimensional feature vectors for each gene capturing signature membership (pre-adipocyte, adipocyte, lipogenic markers), expression statistics (mean, standard deviation, coefficient of variation, maximum), and program-specific expression levels. We then identify the k=5 most similar training genes (from the 122 measured perturbations) using cosine similarity in this feature space, and predict the expression centroid as a weighted average of their measured centroids. To capture biological heterogeneity critical for the MMD metric, we sample 100 cells per perturbation from a Gaussian distribution around the predicted centroid using gene-specific variances learned from control cells. For genes with insufficient feature coverage (<30% non-zero features), we fall back to using the control centroid as a baseline.

# Rationale

The core biological insight driving our model is that genes with similar expression patterns and regulatory properties tend to produce similar perturbation effects when knocked out. This is supported by the observation that transcription factors and genes within the same regulatory modules often have coordinated effects on cell fate decisions. By encoding signature gene membership (pre-adipocyte, adipocyte, lipogenic markers), expression statistics, and program-specific expression levels, we capture functional relationships between genes that are predictive of knockout phenotypes. The k-NN approach is well-suited for this problem because: (1) we have only 122 training perturbations, making complex deep learning models prone to overfitting; (2) gene regulatory networks exhibit local structure where functionally similar genes cluster together; (3) the weighted averaging naturally handles uncertainty by blending multiple similar training examples rather than making hard predictions. The heterogeneity sampling is critical because single-cell data exhibits substantial cell-to-cell variation even within the same perturbation condition, and the MMD evaluation metric specifically measures distribution similarity rather than just mean predictions.

# Data and Resources Used

We used exclusively the provided competition data: obesity_challenge_1.h5ad (44,846 cells Ã— 11,046 genes across 123 perturbations including negative controls) for training, signature_genes.csv containing 888 expert-curated marker genes for the pre-adipocyte, adipocyte, and lipogenic programs, and program_proportion.csv providing ground truth cell state proportions for each measured perturbation. No external datasets, pre-trained gene embeddings (such as Gene2Vec or scGPT), or additional biological annotations (such as Gene Ontology or protein-protein interaction networks) were incorporated. The model was implemented using scikit-learn for k-NN search and StandardScaler normalization, XGBoost for gradient-boosted proportion prediction with regularization to prevent overfitting on the small training set, and standard Python scientific computing libraries (NumPy, SciPy, pandas, AnnData/Scanpy). Feature engineering was performed entirely from the training data by computing per-gene expression statistics across all cells and correlations with program signatures. The approach is computationally efficient, requiring approximately 2-3 minutes for training and 5-10 minutes for full inference on the 2,863 target perturbations, making it suitable for the platform's resource constraints.
